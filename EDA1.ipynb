{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8607e4-947c-4b99-b823-450196f3d9e4",
   "metadata": {},
   "source": [
    "# Ans : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf949066-b612-4dae-a3f6-78eae5d2ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475bce4-d42a-4b7d-b15c-9c56b11fbc02",
   "metadata": {},
   "source": [
    "# Ans : 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94144e56-26a3-4457-b182-de2219fcf525",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Handling missing data can be approached in several ways:\n",
    "\n",
    "Removing Missing Data:\n",
    "\n",
    "Advantages: Simple and effective if the amount of missing data is small.\n",
    "Disadvantages: Can result in significant data loss and potential bias if missing data is not random.\n",
    "Mean/Median Imputation:\n",
    "\n",
    "Advantages: Easy to implement and can be effective if data is missing at random.\n",
    "Disadvantages: Can distort data distribution and reduce variance.\n",
    "Mode Imputation:\n",
    "\n",
    "Advantages: Useful for categorical data.\n",
    "Disadvantages: Can introduce bias if the mode is over-represented.\n",
    "K-Nearest Neighbors (KNN) Imputation:\n",
    "\n",
    "Advantages: Takes into account the similarities between observations, often resulting in better imputations.\n",
    "Disadvantages: Computationally intensive and can be sensitive to outliers.\n",
    "Multiple Imputation:\n",
    "\n",
    "Advantages: Accounts for uncertainty by creating multiple imputations, often resulting in more robust estimates.\n",
    "Disadvantages: Complex to implement and interpret.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3732a9-82f6-43e3-9cc4-24d771733b5d",
   "metadata": {},
   "source": [
    "# Ans : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5950b-cb5c-4b70-a9ec-d808d17ebd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Key factors affecting students' performance in exams include:\n",
    "\n",
    "Study Habits: Frequency and quality of study sessions.\n",
    "Socioeconomic Status: Access to resources and support.\n",
    "Parental Involvement: Level of encouragement and help with studies.\n",
    "School Environment: Quality of teaching and facilities.\n",
    "Mental and Physical Health: Stress levels, nutrition, and sleep.\n",
    "Previous Academic Performance: Past grades and learning foundations.\n",
    "To analyze these factors, you can use:\n",
    "\n",
    "Descriptive Statistics: Summarize data to understand general trends.\n",
    "Correlation Analysis: Identify relationships between different variables.\n",
    "Regression Analysis: Determine the impact of various factors on exam performance.\n",
    "ANOVA: Compare means across different groups (e.g., different study habits).\n",
    "Principal Component Analysis (PCA): Reduce dimensionality and identify key components affecting performance.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea10dd-d1c7-4f46-b9e1-5352005860f6",
   "metadata": {},
   "source": [
    "# Ans : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd8e898-252d-4f64-a2f7-b866ca45ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature engineering involves:\n",
    "\n",
    "Data Cleaning: Handling missing values, correcting errors, and ensuring consistency.\n",
    "Creating New Features: Based on domain knowledge, new features can be derived (e.g., total study hours, average test scores).\n",
    "Encoding Categorical Variables: Convert categorical data into numerical values using techniques like one-hot encoding or label encoding.\n",
    "Scaling and Normalizing: Standardize numerical features to ensure all features contribute equally to the model.\n",
    "Feature Selection: Using techniques like correlation analysis, mutual information, or model-based selection to choose the most relevant features.\n",
    "Transformations: Applying logarithmic, square root, or polynomial transformations to address skewness and improve model performance.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7bca7c-bf79-4bd9-9b64-ae3566a75f47",
   "metadata": {},
   "source": [
    "# Ans : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70562af5-62db-4b51-a0b5-7dde21a5c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To perform EDA, follow these steps:\n",
    "\n",
    "Visualize Distributions: Use histograms, box plots, and Q-Q plots to visualize feature distributions.\n",
    "Summary Statistics: Calculate mean, median, standard deviation, skewness, and kurtosis.\n",
    "Identify Non-Normal Features: Features with high skewness and kurtosis are likely non-normal.\n",
    "Commonly, features like residual sugar, chlorides, and free sulfur dioxide exhibit non-normality in the wine quality dataset.\n",
    "\n",
    "Transformations to improve normality:\n",
    "\n",
    "Log Transformation: Useful for right-skewed data.\n",
    "Square Root Transformation: Also helps in dealing with right-skewed data.\n",
    "Box-Cox Transformation: A more flexible approach that can handle both left and right skewed data.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e067743e-ddef-4084-a3cc-7cf99eb9f83a",
   "metadata": {},
   "source": [
    "# Ans : 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06205828-c53a-49fd-8752-7ed41a03aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To perform PCA:\n",
    "\n",
    "Standardize the Data: Ensure that each feature contributes equally to the analysis.\n",
    "Compute the Covariance Matrix: Determine the relationships between features.\n",
    "Calculate Eigenvalues and Eigenvectors: Identify the principal components.\n",
    "Determine Explained Variance: Calculate the cumulative explained variance to find the number of components needed.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
